---
layout: about
title: About
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic_crop.jpg
  address:

news: false  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page

# USEFUL GUIDE: https://kramdown.gettalong.org/quickref.html
---

ðŸŽ“ PhD student at Oxford's [Torr Vision Group](https://torrvision.com/index.html) working on controllable video generation - keen on making generations more interactive (or even playable)

### ðŸ”¬ Research
- **PhD (2023-Present)**: Working on controlling video diffusion models at Oxford [AIMS CDT](https://aims.robots.ox.ac.uk/), generously funded by [Snap](https://www.snap.com/) studentship
- **MEng Project (2022-2023)**: Enhanced Stable Diffusion 2 sampling diversity using particle-based methods ([project](/projects/repulsion/) Â· [slides](/assets/pdf/masters_presentation.pdf){:target="_blank"})
- **Climate AI (2022)**: Developed meta-learning framework for satellite image inpainting, published at NeurIPS 2022 climate workshop ([paper](https://www.climatechange.ai/papers/neurips2022/24) Â· [project](/projects/convnp/))

### ðŸ’¼ Industry Experience
- **[Humanising Autonomy](https://humanisingautonomy.com/) (6 month internship in 2022)**: Built active learning system and AWS data pipeline for video object detection training
- **[MathWorks](https://www.mathworks.com/) (3 month internship in 2021)**: Developed video action recognition demo and enhanced pooling layers for spatio-temporal operations in [2022a release](https://uk.mathworks.com/help/deeplearning/release-notes.html) of [MATLAB Deep Learning Toolbox](https://uk.mathworks.com/products/deep-learning.html)



<!-- I am a PhD student in Oxford at [Torr Vision Group](https://torrvision.com/index.html) in the [Autonomous Intelligent Machines and Systems](https://aims.robots.ox.ac.uk/) CDT with funding from SNAP. I am doing research in video and 3D generative models including diffusion models. I am very interested in how these models can learn generalisable representations in a compositional fashion.

**Research:** I completed my four year MEng degree in Electronic and Information Engineering (computer engineering) at Imperial College London in 2023. My **Master's project** supervised by [Dr. Yingzhen Li](http://yingzhenli.net/home/en/) focused on increasing the diversity of diffusion model sampling by applying particle based methods to the Stable Diffusion 2 model. This involves adding a repulsion force between image samples and my method allows extra control over what direction we would like to spread results just by augmenting the denoising step. This allows extra control over how users may explore the image space of generations while reducing redundancy in samples. See [project page](/projects/repulsion/) and [slides](/assets/pdf/masters_presentation.pdf){:target="_blank"} for more information.

While in my third year at Imperial, I worked on a research problem involving **inpainting satellite images within a meta-learning framework**. After demonstrating its downstream impact in a water classification setting, our work was accepted in the 2022 NeurIPS climate AI workshop. See [workshop paper](https://www.climatechange.ai/papers/neurips2022/24) and [project page](/projects/convnp/) for more information. I worked with a great team of other Imperial students supervised by [Harrison Zhu](https://harrisonzhu508.github.io/) and got to collaborate with researchers from the University of Copenhagen and Oxford.

**Industrial Experience:** Before starting my final year at Imperial, I completed a 6-month placement at a machine learning startup called **[Humanising Autonomy](https://humanisingautonomy.com/)**, working on building object detection systems to better understand humans. I worked on implementing active learning approaches that find the key frames in videos so that they can be labelled and used for training object detection models in a more data-efficient manner. I then built an automated data ingestion pipeline in AWS, which efficiently gets frames from client videos without human intervention. I also worked on improving the smoothness of object tracking, writing production level Python code and developed a reproducible way of creating demos of the pose estimation and object detection systems on the edge.

I was also previously a software engineering intern at **MathWorks**, where I worked on the [MATLAB Deep Learning Toolbox](https://uk.mathworks.com/products/deep-learning.html). This was a unique experience to code machine learning tools rather than just using them out-of-the-box. I developed a video action recognition classifier based on a research paper in order to demonstrate new functionality in the toolbox and enhanced the pooling layers used in neural networks to allow spatiotemporal operations for the [2022a release](https://uk.mathworks.com/help/deeplearning/release-notes.html). -->


<!-- Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->
